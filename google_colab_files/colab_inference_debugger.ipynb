{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4e24f11",
   "metadata": {},
   "source": [
    "# Colab Inferencing Notebook\n",
    "The purpose of this file is to save and version control the Inferencing.ipynb file in Google Colab.  \n",
    "The code in this file (and colab) will later be used for a .py file that will sent and processed in NRP (Nautilus).  \n",
    "Colab's purpose is to debug this specific file and ensure that there are no errors before being sent to NRP since there is no debugging in NRP.  This file is subject to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c42cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U bitsandbytes\n",
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install peft\n",
    "!pip install transformers\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ba42f6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a1598c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForImageTextToText, AutoProcessor, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "from PIL import Image\n",
    "import json\n",
    "from pathlib import Path\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "# Modify later for Nautilus!\n",
    "MODEL_PATH = \"/content/drive/MyDrive/VLM_MODELS/Qwen2.5-VL-7B-Instruct\"\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/output/waste_detection\"   # Fine-tuned LoRA\n",
    "DATASET_DIR = \"/content/drive/MyDrive/model_datasets/dataset2\"\n",
    "TRAINING_DATA = \"/content/drive/MyDrive/model_datasets/train2.jsonl\"\n",
    "VAL_DATA = \"/content/drive/MyDrive/model_datasets/valid2.jsonl\"\n",
    "\n",
    "print(\"Loading fine-tuned Qwen2.5-VL-7B-Instruct model...\")\n",
    "\n",
    "\n",
    "'''\n",
    "Set up as Lora, change to QLoRA before running \n",
    "'''\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_threshold=6.0,\n",
    ")\n",
    "\n",
    "# Load Base Model\n",
    "base_model = AutoModelForImageTextToText.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# Load LoRA Weights\n",
    "model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    OUTPUT_DIR,\n",
    ")\n",
    "\n",
    "# Load Processor (MUST load from fine-tuned directory)\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    OUTPUT_DIR,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ed3e4e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def run_inference(image_path):\n",
    "    \"\"\"Run inference on a single image.\"\"\"\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an assistant that detects waste objects in images. \"\n",
    "                \"The possible waste categories are: Glass-A, Green waste-A, Metal, Organics-A, \"\n",
    "                \"Organics-B-NOT, Organics-E, Others, Paper-A, Paper-B, Paper-D, \"\n",
    "                \"Plastic-A, Plastic-B, Plastic-C, Plastic-D, Plastic-E, Plastic-G, Wood.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image},\n",
    "                {\"type\": \"text\", \"text\": \"Detect the waste objects in this image and output bounding boxes in Pascal VOC format.\"}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=[image],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1024,\n",
    "            do_sample=False\n",
    "        )\n",
    "\n",
    "    generated_ids = outputs[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    result = processor.decode(generated_ids, skip_special_tokens=True)\n",
    "    return result\n",
    "\n",
    "print(\"Inference function ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be1429",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "TEST_FILE = \"/content/drive/MyDrive/model_datasets/test2.jsonl\"\n",
    "\n",
    "if not Path(TEST_FILE).exists():\n",
    "    print(\"No test.jsonl found. Skipping quick test.\")\n",
    "else:\n",
    "    with open(TEST_FILE, \"r\") as f:\n",
    "        test_example = json.loads(f.readline())\n",
    "\n",
    "    image_path = test_example['messages'][1]['content'][0]['image'].replace(\"file://\", \"\")\n",
    "    ground_truth = test_example['messages'][2]['content']\n",
    "\n",
    "    print(\"Running inference on:\", image_path)\n",
    "    pred = run_inference(image_path)\n",
    "\n",
    "    print(\"\\nPrediction:\\n\", pred)\n",
    "    print(\"\\nGround Truth:\\n\", ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe3a58",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "TEST_FILE = \"/content/drive/MyDrive/model_datasets/test2.jsonl\"\n",
    "results = []\n",
    "\n",
    "if not Path(TEST_FILE).exists():\n",
    "    print(\"No test.jsonl found. Cannot run 5-image test.\")\n",
    "else:\n",
    "    print(\"Running inference on 5 images...\\n\")\n",
    "\n",
    "    test_data = []\n",
    "    with open(TEST_FILE, \"r\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= 5:\n",
    "                break\n",
    "            test_data.append(json.loads(line))\n",
    "\n",
    "    for i, example in enumerate(test_data):\n",
    "        image_path = example['messages'][1]['content'][0]['image'].replace(\"file://\", \"\")\n",
    "        gt = example['messages'][2]['content']\n",
    "\n",
    "        start = time.time()\n",
    "        pred = run_inference(image_path)\n",
    "        end = time.time()\n",
    "\n",
    "        results.append({\n",
    "            \"image_path\": image_path,\n",
    "            \"prediction\": pred,\n",
    "            \"ground_truth\": gt\n",
    "        })\n",
    "\n",
    "        print(f\"Img {i+1}: {Path(image_path).name}\")\n",
    "        print(\"Time:\", round(end-start,1),\"s\")\n",
    "        print()\n",
    "\n",
    "    print(\"Finished 5-image test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf2af8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def parse_detections(text):\n",
    "    dets = []\n",
    "    for line in text.strip().split(\"\\n\"):\n",
    "        parts = line.split()\n",
    "        if len(parts) >= 5:\n",
    "            try:\n",
    "                dets.append({\n",
    "                    \"class\": parts[0],\n",
    "                    \"xmin\": int(parts[1]),\n",
    "                    \"xmax\": int(parts[2]),\n",
    "                    \"ymin\": int(parts[3]),\n",
    "                    \"ymax\": int(parts[4])\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "    return dets\n",
    "\n",
    "if not results:\n",
    "    print(\"No results available. Run Cell 5 first.\")\n",
    "else:\n",
    "    total_pred = 0\n",
    "    total_gt = 0\n",
    "\n",
    "    for r in results:\n",
    "        preds = parse_detections(r[\"prediction\"])\n",
    "        gts   = parse_detections(r[\"ground_truth\"])\n",
    "        total_pred += len(preds)\n",
    "        total_gt += len(gts)\n",
    "\n",
    "    print(\"Total predicted:\", total_pred)\n",
    "    print(\"Total ground truth:\", total_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f6e941",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# The parse_detections function is already defined above (Cell 6)\n",
    "# but redefine for safety in Colab execution order:\n",
    "\n",
    "def parse_detections(text):\n",
    "    dets = []\n",
    "    for line in text.strip().split(\"\\n\"):\n",
    "        parts = line.split()\n",
    "        if len(parts) >= 5:\n",
    "            try:\n",
    "                dets.append({\n",
    "                    \"class\": parts[0],\n",
    "                    \"xmin\": int(parts[1]),\n",
    "                    \"xmax\": int(parts[2]),\n",
    "                    \"ymin\": int(parts[3]),\n",
    "                    \"ymax\": int(parts[4])\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "    return dets\n",
    "\n",
    "# IoU and NMS functions unchanged\n",
    "def calculate_iou(a, b):\n",
    "    x1 = max(a['xmin'], b['xmin'])\n",
    "    y1 = max(a['ymin'], b['ymin'])\n",
    "    x2 = min(a['xmax'], b['xmax'])\n",
    "    y2 = min(a['ymax'], b['ymax'])\n",
    "\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return 0.0\n",
    "\n",
    "    inter = (x2 - x1) * (y2 - y1)\n",
    "    area1 = (a['xmax'] - a['xmin']) * (a['ymax'] - a['ymin'])\n",
    "    area2 = (b['xmax'] - b['xmin']) * (b['ymax'] - b['ymin'])\n",
    "    union = area1 + area2 - inter\n",
    "\n",
    "    return inter / union if union > 0 else 0.0\n",
    "\n",
    "def apply_nms(dets, thr=0.5):\n",
    "    if not dets:\n",
    "        return []\n",
    "    dets = sorted(dets, key=lambda d: (d['xmax']-d['xmin'])*(d['ymax']-d['ymin']), reverse=True)\n",
    "    keep=[]\n",
    "    for d in dets:\n",
    "        good=True\n",
    "        for k in keep:\n",
    "            if d[\"class\"]==k[\"class\"] and calculate_iou(d,k)>thr:\n",
    "                good=False\n",
    "                break\n",
    "        if good:\n",
    "            keep.append(d)\n",
    "    return keep\n",
    "\n",
    "# GPT did this \"Simplified for Colab\", may cause an error!\n",
    "\n",
    "#def get_class_color(cls):\n",
    "#   return \"orange\"\n",
    "\n",
    "def get_class_color(class_name):\n",
    "    \"\"\"Assign consistent colors to classes\"\"\"\n",
    "    color_map = {\n",
    "        'Plastic-E': 'orange',\n",
    "        'Plastic-A': 'darkorange',\n",
    "        'Plastic-B': 'coral',\n",
    "        'Plastic-C': 'orangered',\n",
    "        'Plastic-D': 'tomato',\n",
    "        'Plastic-G': 'chocolate',\n",
    "        'Paper-A': 'cyan',\n",
    "        'Paper-B': 'turquoise',\n",
    "        'Paper-D': 'deepskyblue',\n",
    "        'Metal': 'gray',\n",
    "        'Wood-C': 'magenta',\n",
    "        'Glass-A': 'lime',\n",
    "        'Organics-A': 'yellow',\n",
    "        'Organics-B-NOT': 'gold',\n",
    "        'Organics-E': 'khaki',\n",
    "        'Green waste-A': 'limegreen',\n",
    "        'Others': 'white'\n",
    "    }\n",
    "    return color_map.get(class_name, 'red')\n",
    "\n",
    "print(\"Visualization functions loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be63ba68",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if not results:\n",
    "    print(\"No results available. Run Cell 5 first.\")\n",
    "else:\n",
    "    for i in range(len(results)):\n",
    "        print(f\"Showing image {i+1}/{len(results)}\")\n",
    "        image_path = results[i][\"image_path\"]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        preds = apply_nms(parse_detections(results[i][\"prediction\"]))\n",
    "\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.imshow(image)\n",
    "        ax = plt.gca()\n",
    "\n",
    "        for det in preds:\n",
    "            x1,y1 = det[\"xmin\"], det[\"ymin\"]\n",
    "            w = det[\"xmax\"] - det[\"xmin\"]\n",
    "            h = det[\"ymax\"] - det[\"ymin\"]\n",
    "            rect = patches.Rectangle((x1,y1), w, h, linewidth=2, edgecolor='orange', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(x1, y1, det[\"class\"], color=\"white\", backgroundcolor=\"orange\")\n",
    "\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86faf3bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def show_coordinate_system():\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ax.set_xlim(0,100)\n",
    "    ax.set_ylim(0,100)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(\"Pascal VOC Coordinates (Top-Left Origin)\")\n",
    "    ax.scatter([0],[0],c=\"red\",s=100)\n",
    "    ax.text(5,5,\"(0,0)\",color=\"red\")\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "show_coordinate_system()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
